---
name: testmanager
description: "Tiefgehendes DomÃ¤nenwissen fÃ¼r Test Management nach ISTQB-Standard: Testdesign-Techniken (Ã„quivalenzklassen, Grenzwertanalyse, Entscheidungstabellen, Zustandstransitionen), Coverage-Strategien, Teststufen, Testberichterstattung, Azure DevOps Test Plans Integration und deterministische Testfall-Formulierung. Verwende diesen Skill wenn TestfÃ¤lle erstellt, Teststrategien definiert, Coverage-Matrizen aufgebaut, Testberichte geschrieben, ADO Test Plans verwaltet oder Expected Results formuliert werden. Triggers: ISTQB, Testfall, Test Case, Teststrategie, Testplan, Coverage, Abdeckung, Testbericht, Expected Result, Testdesign, Grenzwert, Ã„quivalenzklasse, Entscheidungstabelle, ZustandsÃ¼bergang, ADO Test Plan, TestausfÃ¼hrung, Regressiontest, Abnahmetest."
---

# Test Management DomÃ¤nenwissen

Dieses Skill liefert das Fach- und Methodenwissen fÃ¼r den Testmanager Agent. Der Agent orchestriert â€” dieser Skill liefert die inhaltliche Tiefe.

## ISTQB-Testprozess

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Planung  â”‚â”€â”€â–¶â”‚ Analyse  â”‚â”€â”€â–¶â”‚  Design  â”‚â”€â”€â–¶â”‚Implementierungâ”‚â”€â”€â–¶â”‚DurchfÃ¼hrungâ”‚â”€â”€â–¶â”‚ Abschlussâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Strategie,     Was testen?    Wie testen?    TestfÃ¤lle,         Tests laufen    Report,
 Ressourcen,    Testbedingungen Techniken     Testdaten,          lassen,         Lessons
 Zeitplan       identifizieren  wÃ¤hlen        Umgebung            Ergebnisse      Learned
                                              vorbereiten         dokumentieren
```

## Teststufen

| Stufe | Fokus | Basis | Verantwortung | Typische Werkzeuge |
|-------|-------|-------|---------------|-------------------|
| **Komponententest** | Einzelne Units isoliert | Code, Detaildesign | Entwickler | xUnit, NUnit, Moq |
| **Integrationstest** | Zusammenspiel von Komponenten | Schnittstellenspez. | Entwickler/Tester | Testcontainers, WireMock |
| **Systemtest** | Gesamtsystem gegen Anforderungen | Anforderungsspez. | Tester | Playwright, Postman |
| **Abnahmetest** | Business-Anforderungen, Benutzersicht | GeschÃ¤ftsprozesse | PO/Tester/Endbenutzer | ADO Test Plans |

## Testdesign-Techniken

Detaillierte Techniken mit Beispielen: Siehe [references/testdesign-techniken.md](references/testdesign-techniken.md)

### Technik-Auswahl nach Situation

| Situation | Empfohlene Technik | BegrÃ¼ndung |
|-----------|-------------------|-----------|
| Eingabefelder mit Wertebereichen | Ã„quivalenzklassen + Grenzwertanalyse | Systematische Abdeckung mit minimaler Testanzahl |
| GeschÃ¤ftsregeln mit Bedingungen | Entscheidungstabelle | Alle Bedingungskombinationen sichtbar |
| Workflows mit StatusÃ¼bergÃ¤ngen | Zustandstransitionstest | Zustandsmaschine vollstÃ¤ndig abdecken |
| Komplexe Benutzerprozesse | Anwendungsfallbasiertes Testen | Realistische End-to-End-Szenarien |
| Erfahrungsbasiertes Testen | Error Guessing + Exploratives Testen | Defekte finden, die Techniken Ã¼bersehen |

## Deterministische Testfall-Formulierung

### Expected Results â€” Goldstandard

**Regel:** Jedes Expected Result muss so prÃ¤zise sein, dass zwei verschiedene Tester zum **gleichen Ergebnis** kommen (bestanden/nicht bestanden).

| QualitÃ¤tsstufe | Beispiel | Bewertung |
|-------------|---------|-----------|
| âŒ Schlecht | "Ergebnis wird angezeigt" | Nicht verifizierbar â€” WAS wird WO WIE angezeigt? |
| âš ï¸ Mittel | "Fehlermeldung wird angezeigt" | Welche Meldung? Wo? |
| âœ… Gut | "Inline-Fehlermeldung 'Bitte geben Sie eine gÃ¼ltige E-Mail-Adresse ein' erscheint unter dem Feld 'E-Mail' in roter Schrift (#D82034)" | Deterministisch prÃ¼fbar |

### Checkliste fÃ¼r Expected Results

- [ ] **WAS** passiert? (Konkretes Systemverhalten)
- [ ] **WO** wird es sichtbar? (Element, Seite, Bereich)
- [ ] **WIE** sieht es aus? (Format, Farbe, Text)
- [ ] **WANN** passiert es? (Sofort, nach Delay, nach BestÃ¤tigung)
- [ ] **Welche Werte?** (Konkrete Zahlen, Texte, Formate)
- [ ] **Was passiert NICHT?** (Keine DatenÃ¤nderung, keine Navigation, kein Datenverlust)

### Muster fÃ¼r Expected Results nach Aktionstyp

| Aktionstyp | Expected-Result-Muster |
|-----------|----------------------|
| **Formular absenden** | "Erfolgsmeldung '[Text]' erscheint. Datensatz ist in der Liste sichtbar mit Werten [A], [B], [C]. URL wechselt zu [/pfad]." |
| **Validierungsfehler** | "Inline-Fehlermeldung '[Text]' unter Feld '[Name]'. Formular bleibt offen. Speichern-Button ist deaktiviert. Keine Daten wurden gespeichert." |
| **LÃ¶schen** | "BestÃ¤tigungsdialog mit Text '[Text]' erscheint. Nach BestÃ¤tigung: Datensatz ist aus der Liste entfernt. Meldung '[Text]'. ZugehÃ¶rige [VerknÃ¼pfungen] sind bereinigt." |
| **Navigation** | "Seite '[Titel]' wird geladen. URL ist [/pfad]. Breadcrumb zeigt [A > B > C]. Ladezeit < [n]s." |
| **Statuswechsel** | "Status-Badge wechselt von '[Alt]' auf '[Neu]' (Farbe: [Farbe]). Timestamp 'Letzte Ã„nderung' ist aktualisiert auf [Format]. Audit-Log enthÃ¤lt Eintrag mit [Details]." |
| **E-Mail-Versand** | "E-Mail wird an [Adresse] gesendet. Betreff: '[Text]'. Inhalt enthÃ¤lt [SchlÃ¼sselinformationen]. Absender ist [Adresse]." |
| **Dateiexport** | "Datei '[Name].[Format]' wird heruntergeladen. DateigrÃ¶sse > 0 Bytes. Inhalt enthÃ¤lt [erwartete Spalten/Zeilen]. Encoding: UTF-8." |

## Coverage-Analyse

### Coverage-Matrix-Aufbau

```
Anforderung (AC)    â†’    Testbedingung    â†’    Testfall    â†’    Testergebnis
     1:1                    1:n                  n:1              1:1
```

| Kennzahl | Formel | Zielwert |
|----------|--------|----------|
| **AC-Coverage** | Getestete ACs / Alle ACs Ã— 100% | â‰¥ 85% (Standard), â‰¥ 95% (Hoch-Risiko) |
| **Testfall-Effizienz** | Gefundene Defekte / Anzahl TestfÃ¤lle | HÃ¶her = effizienter |
| **Redundanz** | Doppelt abgedeckte ACs / Alle ACs | < 10% (wenig Redundanz) |

### Coverage-Typen

| Typ | Beschreibung | Wann einsetzen |
|-----|-------------|---------------|
| **Anforderungsbasiert** | Jede Anforderung / jedes AC mindestens 1x getestet | Immer (Baseline) |
| **Risikobasiert** | Hohe Risiken haben mehr Tests | Bei knappem Budget/Zeit |
| **Codebasiert** | Line/Branch Coverage | Komponententests |
| **Explorativ** | Session-basiert, erfahrungsgetrieben | ErgÃ¤nzend zu strukturierten Tests |

## Teststrategie nach Risiko

### Risikobasierte Testpriorisierung

| Risikostufe | Wahrscheinlichkeit Ã— Auswirkung | Teststrategie |
|------------|-------------------------------|--------------|
| **Kritisch** (R1) | Hoch Ã— Hoch | VollstÃ¤ndige Abdeckung: Positiv + Negativ + Grenzwert + Integration + Performance |
| **Hoch** (R2) | Hoch Ã— Mittel ODER Mittel Ã— Hoch | Positiv + Negativ + Grenzwert + ausgewÃ¤hlte Integration |
| **Mittel** (R3) | Mittel Ã— Mittel | Positiv + wichtigste Negativ-Tests |
| **Niedrig** (R4) | Niedrig Ã— beliebig ODER beliebig Ã— Niedrig | Happy Path + Stichproben |

### Risikobewertung fÃ¼r TestfÃ¤lle

| Faktor | Hoch | Mittel | Niedrig |
|--------|------|--------|---------|
| **GeschÃ¤ftskritikalitÃ¤t** | Kernprozess, regulatorisch | UnterstÃ¼tzungsprozess | Nice-to-have |
| **BenutzerhÃ¤ufigkeit** | TÃ¤glich, viele Benutzer | WÃ¶chentlich, wenige Benutzer | Selten, Admin-Only |
| **Technische KomplexitÃ¤t** | Viele Schnittstellen, Async | Moderate Logik | Einfaches CRUD |
| **Ã„nderungshistorie** | HÃ¤ufig geÃ¤ndert, fehleranfÃ¤llig | Gelegentlich geÃ¤ndert | Stabil seit Langem |

## Azure DevOps Test Plans Integration

### Testfall-Erstellung via MCP

```
1. mcp_ado_testplan_list_test_plans     â†’ VerfÃ¼gbare TestplÃ¤ne
2. mcp_ado_testplan_list_test_suites    â†’ Test Suites im Plan
3. mcp_ado_testplan_create_test_case    â†’ Neuen Testfall erstellen
4. mcp_ado_testplan_add_test_cases_to_suite â†’ TestfÃ¤lle zur Suite hinzufÃ¼gen
5. mcp_ado_wit_link_work_item_to_pull_request â†’ Testfall mit PBI verlinken
```

### Testfall-Verlinkung (Pflicht)

```
Work Item (PBI/Feature)
    â”‚
    â”œâ”€â”€ Tested By â”€â”€â–¶ Test Case 1
    â”œâ”€â”€ Tested By â”€â”€â–¶ Test Case 2
    â””â”€â”€ Tested By â”€â”€â–¶ Test Case 3
```

**Regeln:**
- Jeder Testfall ist via "Tested By" mit dem Work Item verlinkt
- Jedes AC hat mindestens 1 Testfall
- TestfÃ¤lle tragen den Tag `Ai Gen` â€” **kein anderer Tag** (ausser explizit vom Benutzer vorgegeben). Bestehende Tags beibehalten.
- Nummerierung: Fortlaufend (1, 2, 3 ...), bei Selektion umnummerieren

### ADO Test Case Format

```
Title:          TC-[Nr]: [AussagekrÃ¤ftiger, aktionsorientierter Titel]
Area Path:      [Gleicher Area Path wie das verlinkte Work Item]
Tags:           Ai Gen
Assigned To:    [Optional]

Test Steps:
  Step 1: [Aktion]
    Expected Result: [Detailliertes, deterministisches Ergebnis]
  Step 2: [Aktion]
    Expected Result: [Detailliertes, deterministisches Ergebnis]

Preconditions:
  - [Vorbedingung 1]
  - [Vorbedingung 2]
```

## Testberichterstattung

### Testbericht-Template

```markdown
# Testbericht: [Work Item / Feature Titel]

**Datum:** [TT.MM.YYYY] | **Tester:** [Name/AI] | **Gesamtstatus:** ðŸŸ¢/ðŸŸ¡/ðŸ”´

## Zusammenfassung

| Kennzahl | Wert |
|----------|------|
| TestfÃ¤lle gesamt | [n] |
| Bestanden | [n] ([%]%) |
| Fehlgeschlagen | [n] ([%]%) |
| Blockiert | [n] ([%]%) |
| Nicht ausgefÃ¼hrt | [n] ([%]%) |
| AC-Abdeckung | [n/m] ([%]%) |

## Defekte

| # | Testfall | Fehlerbeschreibung | Schweregrad | Status |
|---|---------|--------------------| ------------|--------|
| 1 | TC-[Nr] | [Was ist passiert vs. was erwartet war] | Kritisch/Hoch/Mittel/Niedrig | Offen/In Arbeit/GelÃ¶st |

## Risikobewertung

| Bereich | Restrisiko | BegrÃ¼ndung |
|---------|-----------|-----------|
| [Bereich] | Hoch/Mittel/Niedrig | [Warum?] |

## Empfehlung

[Go / No-Go mit BegrÃ¼ndung. Bei No-Go: Was muss noch passieren?]
```

### Schweregrad-Definitionen

| Schweregrad | Definition | Reaktion |
|------------|-----------|---------|
| **Kritisch** | System unbenutzbar, Datenverlust, SicherheitslÃ¼cke | Sofort beheben, Release blockiert |
| **Hoch** | Kernfunktion beeintrÃ¤chtigt, kein Workaround | Vor Release beheben |
| **Mittel** | Funktion beeintrÃ¤chtigt, Workaround vorhanden | Im nÃ¤chsten Sprint beheben |
| **Niedrig** | Kosmetisch, geringe Auswirkung | Backlog, nach PrioritÃ¤t |

## Regressionstest-Strategie

### Wann Regressionstests?

| AuslÃ¶ser | Regressions-Scope |
|----------|-------------------|
| Neues Feature | Betroffene bestehende Funktionen + Schnittstellen |
| Bugfix | Fix-Verifikation + verwandte Funktionen |
| Konfigurations-Ã„nderung | Alle betroffenen Features |
| Release | Kritische Pfade + Smoke Tests |

### Smoke-Test-Set (Minimum fÃ¼r jedes Release)

1. Login/Logout funktioniert
2. Hauptnavigation erreichbar
3. Kernprozess 1 (Happy Path) durchlÃ¤uft
4. Kernprozess 2 (Happy Path) durchlÃ¤uft
5. Daten werden korrekt angezeigt (Stichprobe)
6. Keine JavaScript-/API-Fehler in der Konsole
